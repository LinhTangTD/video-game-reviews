---
title: "Models"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(xgboost)
library(dplyr)
library(readr)
library(leaps)
library(caret)
library(pls)
library(randomForest)
library(ggplot2)
```

```{r}
setwd('/Users/linhtang/Desktop/STA-395/Code')
df = read_csv("clean_data/clean_data_model.csv", na = "missing")

# Add new var whether game is developed and published by same company
df$is_same_dev_pub = df$developers == df$publishers

# check the number of missing values in each variable
# sapply(final_df, function(x) sum(is.na(x)))

# Drop unnecessary variables for the model
# platforms -> company
# developers, publishers -> is_same_dev_pub
# release_date -> years_since_released
# esrb_descs -> dummy vars
# remove allow_multiplayer and allow_online because they contain so many missing values, 10146 and 7482 respectively
df = dplyr::select(df, -c(platform, developers, publishers, release_date, esrb_descs, allow_multiplayer, allow_online))

# change to factor
df$esrb_ratings = factor(df$esrb_ratings) #, order = TRUE, levels =c('K-A', 'E', 'E10+', 'T', 'M', 'A0', 'RP'))
df$company = as.factor(df$company)

# Remove NAs observation
final_df = df[complete.cases(df),]
model_df = dplyr::select(final_df, -title)
names(model_df) <- make.names(names(model_df))
```

```{r}
## 75% of the sample size
smp_size <- floor(0.75 * nrow(model_df))

## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(model_df)), size = smp_size)

train <- model_df[train_ind, ]
test <- model_df[-train_ind, ]

X_train = model.matrix(user_score ~ ., data = train)
y_train = train$user_score
X_test = model.matrix(user_score ~ ., data = test)
y_test = test$user_score
```

DO NOT RUN THE CODE BELOW

```{r}
# RF model with all 194 predictors
set.seed(1234)
rf.fit <- randomForest(x = X_train, y = y_train, importance=TRUE)
# save the model to disk
saveRDS(rf.fit, "./rf_model.rds")

# Feature Selection for Random Forest using cross-validation
set.seed(1234)
rfcv.fit = rfcv(X_train, y_train)
# save the model to disk
saveRDS(rfcv.fit, "./rfcv_model.rds")
```

### Plot variable selection graph

```{r}
rfcv.fit <- readRDS("./rfcv_model.rds") #random forest cross validation model

plot(rfcv.fit$n.var, rfcv.fit$error.cv, xlab="Number of Variables", ylab="Cross Validation Error", main = "Estimated Error by Number of Variables", ylim = c(95, 135), xlim = c(0, 202), type="o", lwd=2)

lines(rfcv.fit$n.var[order(rfcv.fit$n.var)], rfcv.fit$error.cv[order(rfcv.fit$n.var)], pch=16)

text(rfcv.fit$n.var+5, rfcv.fit$error.cv+2, labels=round(rfcv.fit$error.cv))
```

Using the results from the random forest cross validation model above, we can plot the cross validation error rate by the number of predictors used in the model. As seen in the plot below, the error rate drop significantly as the model predictors increase from 1 to 24. As the predictors are increased from 24 to 194, the error rate starts to level off.

```{r}
rfcv.fit$error.cv
```

Now we fit a random forest model with all predictors to determine the 24 most important predictors to use in our final model.

```{r}
# load pre-trained model
rf.fit.all <- readRDS("./rf_model.rds")

# predictors with their importance value
import_var <- as.data.frame(importance(rf.fit.all))

# get 24 "most important" predictors
import_var = import_var[order(-import_var$`%IncMSE`),][1:24,]
rownames(import_var)
```

### Performance Evaluation

```{r}
# Final RF model with 24 predictors
set.seed(1234)
rf.fit <- randomForest(x = X_train[, rownames(import_var)], y = y_train, importance=TRUE)
# save the model to disk
saveRDS(rf.fit, "./rf_model_final.rds")
```

```{r}
rf.fit <- readRDS("./rf_model_final.rds")

# use model to predict test set
rf_prediction <- predict(rf.fit, X_test[, rownames(import_var)])

# calculate RMSE
RMSE(y_test, rf_prediction) # 4.195301 # 9.698178 # 9.755624

# R-squared
1 - var(y_test - rf_prediction) / var(y_test) # 0.9029293 # 0.4814148 # 0.4741155
```

### Visualize variable importance

```{r}
import_var$Var.Names <- row.names(import_var)

ggplot(import_var, aes(x=Var.Names, y=`%IncMSE`)) +
  geom_segment( aes(x=Var.Names, xend=Var.Names, y=0, yend=`%IncMSE`), color="skyblue") +
  theme_light() +
  coord_flip() +
  theme(
    legend.position="bottom",
    panel.grid.major.y = element_blank(),
    panel.border = element_blank(),
    axis.ticks.y = element_blank()
  ) +
    labs(
      x     = "Feature",
      y     = "Importance",
      title = "Feature Importance of RF Model"
    )

varImpPlot(rf.fit, type = 1)

plot(y_test ~ rf_prediction, pch=20, xlab="fitted", ylab="actual", main="Random Forest Goodness-of-fit")
grid(); abline(0,1)

plot(rf.fit)
```
