---
title: "Models"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(xgboost)
library(dplyr)
library(readr)
library(leaps)
library(caret)
library(pls)
```

```{r}
setwd('/Users/linhtang/Desktop/STA-395/Code')
df = read_csv("clean_data/clean_data_model.csv", na = "missing")

# new var whether game is developed and published by same company
df$same_dev_pub = df$developers == df$publishers

# drop unnecessary for the model
colnames(df)
df2 = dplyr::select(df, -c(title, platform, developers, publishers, release_date, esrb_descs))

# change to factor
df2$esrb_ratings = as.factor(df2$esrb_ratings)
df2$company = as.factor(df2$company)

# Remove NAs observation
df3 = df2[complete.cases(df2),]
```

```{r}
# build linear regression model
all = regsubsets(user_score~., data = df3, method = "seqrep", nbest = 1, nvmax = 15)
reg_summary = summary(all)

# Set up a 2x2 grid so we can look at 4 plots at once
par(mfrow = c(2,2))
plot(reg_summary$rss, xlab = "Number of Variables", ylab = "RSS", type = "l")
plot(reg_summary$adjr2, xlab = "Number of Variables", ylab = "Adjusted RSq", type = "l")

# We will now plot a red dot to indicate the model with the largest adjusted R^2 statistic.
# The which.max() function can be used to identify the location of the maximum point of a vector
adj_r2_max = which.max(reg_summary$adjr2) # 11

# The points() command works like the plot() command, except that it puts points 
# on a plot that has already been created instead of creating a new plot
points(adj_r2_max, reg_summary$adjr2[adj_r2_max], col ="red", cex = 2, pch = 20)

# We'll do the same for C_p and BIC, this time looking for the models with the SMALLEST statistic
plot(reg_summary$cp, xlab = "Number of Variables", ylab = "Cp", type = "l")
cp_min = which.min(reg_summary$cp) # 10
points(cp_min, reg_summary$cp[cp_min], col = "red", cex = 2, pch = 20)

plot(reg_summary$bic, xlab = "Number of Variables", ylab = "BIC", type = "l")
bic_min = which.min(reg_summary$bic) # 6
points(bic_min, reg_summary$bic[bic_min], col = "red", cex = 2, pch = 20)

# Look at coefficients of our "best-selected" variables
coef(all, id=which.min(reg_summary$bic)) # 12 variables
```

```{r, echo=FALSE}
# Stepwise Regression using AIC
nullmodel<- lm(user_score~1, data = df3)
fullmodel<- lm(user_score~., data = df3)
model.step.s <- step(nullmodel, scope=list(lower=nullmodel, upper=fullmodel), direction='both')

model.sum = summary(model.step.s)
model.sum
```

```{r}
# Set seed for reproducibility
set.seed(123)
# Set up repeated k-fold cross-validation
train.control <- trainControl(method = "cv", number = 10)
# Train the model
step.model <- train(user_score ~., data = df3,
                    method = "leapSeq", 
                    tuneGrid = data.frame(nvmax = 1:52),
                    trControl = train.control
                    )
step.model$results
step.model$bestTune
```


```{r}
#make this example reproducible
set.seed(0)

#fit PCR model
model <- pcr(user_score ~ ., data=df3, scale=TRUE, validation="CV")
```


```{r xgboost}
#make this example reproducible
set.seed(0)

#split into training (80%) and testing set (20%)
parts = createDataPartition(data$medv, p = .8, list = F)
train = data[parts, ]
test = data[-parts, ]

#define predictor and response variables in training set
train_x = data.matrix(train[, -13])
train_y = train[,13]

#define predictor and response variables in testing set
test_x = data.matrix(test[, -13])
test_y = test[, 13]

#define final training and testing sets
xgb_train = xgb.DMatrix(data = train_x, label = train_y)
xgb_test = xgb.DMatrix(data = test_x, label = test_y)

#define watchlist
watchlist = list(train=xgb_train, test=xgb_test)

#fit XGBoost model and display training and testing data at each round
model = xgb.train(data = xgb_train, max.depth = 3, watchlist=watchlist, nrounds = 100)

#calculate the following accuracy measures for the model
mean((test_y - pred_y)^2) #mse
caret::MAE(test_y, pred_y) #mae
caret::RMSE(test_y, pred_y) #rmse
```

```{r}
# id: model id
# object: regsubsets object
# data: data used to fit regsubsets
# outcome: outcome variable
get_model_formula <- function(id, object, outcome){
  # get models data
  models <- summary(object)$which[id,-1]
  # Get outcome variable
  #form <- as.formula(object$call[[2]])
  #outcome <- all.vars(form)[1]
  # Get model predictors
  predictors <- names(which(models == TRUE))
  predictors <- paste(predictors, collapse = "+")
  # Build model formula
  as.formula(paste0(outcome, "~", predictors))
}

#get the cross-validation (CV) error for a given model
get_cv_error <- function(model.formula, data){
  set.seed(1)
  train.control <- trainControl(method = "cv", number = 5)
  cv <- train(model.formula, data = data, method = "lm",
              trControl = train.control)
  cv$results$RMSE
}

# Compute cross-validation error
model.ids <- 1:12
cv.errors <-  map(model.ids, get_model_formula, models, "Fertility") %>%
  map(get_cv_error, data = swiss) %>%
  unlist()
cv.errors

# Cross Validation
fit.control <- trainControl(method = "repeatedcv", number = 5, repeats = 10)
colnames(df2) <- make.names(colnames(df2))
set.seed(123)  
fit1 <- train(user_score ~ ., data = df2, method = "rpart", trControl = fit.control, na.action = na.pass)
fit1$resample
```